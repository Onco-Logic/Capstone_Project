<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/pages/CancerGenetics.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/pages/CancerGenetics.py" />
              <option name="originalContent" value="import streamlit as st&#10;import numpy as np&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import os&#10;import sys&#10;from matplotlib.lines import Line2D&#10;from sklearn.cluster import KMeans&#10;from sklearn.preprocessing import StandardScaler, FunctionTransformer&#10;from sklearn.decomposition import PCA&#10;from sklearn.feature_selection import VarianceThreshold&#10;from sklearn.base import BaseEstimator, TransformerMixin&#10;from sklearn.metrics import (&#10;    confusion_matrix, classification_report,&#10;    accuracy_score, balanced_accuracy_score,&#10;    precision_score, recall_score, f1_score,&#10;    ConfusionMatrixDisplay, silhouette_score&#10;)&#10;from sklearn.model_selection import StratifiedKFold&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.ensemble import RandomForestClassifier&#10;from sklearn.linear_model import SGDClassifier&#10;from sklearn.pipeline import Pipeline&#10;&#10;# Add the scripts directory to Python path&#10;sys.path.append(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'scripts'))&#10;from custom_transformers import UMAPTransformer, TopKVarianceSelector&#10;&#10;import shap&#10;import joblib&#10;&#10;&#10;# Set page config after imports - must be called before any other Streamlit commands&#10;st.set_page_config(initial_sidebar_state=&quot;collapsed&quot;)&#10;&#10;# ────────────────────────────────────────────&#10;# Plot helpers (silhouette removed from evaluate_clusters)&#10;# ────────────────────────────────────────────&#10;def evaluate_clusters(name, X, cluster_labels, true_labels):&#10;    from sklearn.metrics import (&#10;        adjusted_rand_score, normalized_mutual_info_score,&#10;        homogeneity_score, completeness_score, v_measure_score&#10;    )&#10;    y_true = true_labels.astype(str).values&#10;    y_pred = pd.Series(cluster_labels).astype(str)&#10;    scores = {&#10;        &quot;ARI&quot;: adjusted_rand_score(y_true, y_pred),&#10;        &quot;NMI&quot;: normalized_mutual_info_score(y_true, y_pred),&#10;        &quot;Homogeneity&quot;: homogeneity_score(y_true, y_pred),&#10;        &quot;Completeness&quot;: completeness_score(y_true, y_pred),&#10;        &quot;V-measure&quot;: v_measure_score(y_true, y_pred),&#10;    }&#10;    st.write({k: f&quot;{v:.3f}&quot; for k, v in scores.items()})&#10;    # silhouette handled in plot_step&#10;&#10;&#10;def plot_step(name, X2d, clust, Xfull, labels):&#10;    col1, col2 = st.columns(2)&#10;    with col1:&#10;        st.markdown(f&quot;#### {name}: K‑Means clusters&quot;)&#10;        fig, ax = plt.subplots(figsize=(5, 4))&#10;        pts = ax.scatter(X2d[:, 0], X2d[:, 1], c=clust, cmap=&quot;viridis&quot;, alpha=0.6)&#10;        fig.colorbar(pts, ax=ax, label=&quot;Cluster&quot;)&#10;        st.pyplot(fig)&#10;    with col2:&#10;        st.markdown(f&quot;#### {name}: True labels&quot;)&#10;        codes, classes = pd.factorize(labels)&#10;        fig, ax = plt.subplots(figsize=(5, 4))&#10;        ax.scatter(X2d[:, 0], X2d[:, 1], c=codes, cmap=&quot;tab10&quot;, alpha=0.6)&#10;        handles = [&#10;            Line2D([0], [0], marker='o', color='w',&#10;                   markerfacecolor=plt.cm.tab10(i / max(1, len(classes))),&#10;                   label=cls)&#10;            for i, cls in enumerate(classes)&#10;        ]&#10;        ax.legend(handles=handles, title=&quot;Class&quot;,&#10;                  bbox_to_anchor=(1.05, 1), loc=&quot;upper left&quot;)&#10;        st.pyplot(fig)&#10;&#10;    # cluster metrics&#10;    evaluate_clusters(name, Xfull, clust, labels)&#10;    # correct silhouette&#10;    if name == &quot;Filtered-UMAP&quot;:&#10;        st.write(f&quot;Silhouette (2D): {silhouette_score(X2d, clust):.3f}&quot;)&#10;    elif Xfull.shape[1] &gt;= 2:&#10;        st.write(f&quot;Silhouette: {silhouette_score(Xfull, clust):.3f}&quot;)&#10;&#10;&#10;# ────────────────────────────────────────────&#10;# Load &amp; merge data (cached)&#10;# ────────────────────────────────────────────&#10;@st.cache_data&#10;def load_data():&#10;    df_x = pd.read_csv(&quot;Data/cancer_subtype_data.csv&quot;)&#10;    df_y = pd.read_csv(&quot;Data/cancer_subtype_labels.csv&quot;)&#10;    df = pd.merge(df_x, df_y).drop(df_x.columns[0], axis=1)&#10;    return df&#10;&#10;&#10;# Common list of tags&#10;tags = [&#10;    &quot;Original&quot;,&#10;    &quot;Threshold-Filtered&quot;,&#10;    &quot;Threshold-Filtered (log)&quot;,&#10;    &quot;Filtered-UMAP&quot;,&#10;    &quot;Selection-Top-350&quot;,&#10;    &quot;Selection-Top-350 (log)&quot;&#10;]&#10;model_dir = &quot;resources/CancerGeneticsModels&quot;&#10;&#10;model_specs = [&#10;    (DecisionTreeClassifier, {}, &quot;Decision Tree&quot;),&#10;    (RandomForestClassifier, {}, &quot;Random Forest&quot;),&#10;    (SGDClassifier, {&quot;loss&quot;: &quot;log_loss&quot;, &quot;penalty&quot;: &quot;l2&quot;, &quot;max_iter&quot;: 1000}, &quot;SGD Classifier&quot;)&#10;]&#10;&#10;&#10;# ────────────────────────────────────────────&#10;# Compute EDA transforms per‑tag (cached)&#10;# ────────────────────────────────────────────&#10;@st.cache_data(show_spinner=False)&#10;def compute_eda(tag: str):&#10;    df = load_data()&#10;    X = df.drop(columns=&quot;Class&quot;)&#10;    y = df[&quot;Class&quot;]&#10;&#10;    if tag == &quot;Original&quot;:&#10;        Xs = StandardScaler().fit_transform(X)&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Threshold-Filtered&quot;:&#10;        sel = VarianceThreshold(0.5).fit(X)&#10;        Xf = X.loc[:, sel.get_support()]&#10;        Xs = StandardScaler().fit_transform(Xf)&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Threshold-Filtered (log)&quot;:&#10;        Xlog = np.log1p(X)&#10;        sel = VarianceThreshold(0.5).fit(Xlog)&#10;        Xf = Xlog.loc[:, sel.get_support()]&#10;        Xs = Xf.values&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Filtered-UMAP&quot;:&#10;        Xs = StandardScaler().fit_transform(X)&#10;        Emb = UMAPTransformer(&#10;            n_components=100, n_neighbors=5, min_dist=1.0, random_state=42&#10;        ).fit_transform(Xs)&#10;        X2d = Emb[:, :2]&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Emb)&#10;        return X2d, cl, Emb, y&#10;&#10;    if tag == &quot;Selection-Top-350&quot;:&#10;        top = X.var().sort_values(ascending=False).head(350).index&#10;        Xf = X[top]&#10;        Xs = StandardScaler().fit_transform(Xf)&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Selection-Top-350 (log)&quot;:&#10;        Xlog = np.log1p(X)&#10;        top = Xlog.var().sort_values(ascending=False).head(350).index&#10;        Xf = Xlog[top]&#10;        Xs = Xf.values&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    raise ValueError(f&quot;Unknown tag {tag}&quot;)&#10;&#10;&#10;# ────────────────────────────────────────────&#10;# Modeling pipelines &amp; model IO helpers&#10;# ────────────────────────────────────────────&#10;def get_pipeline(tag):&#10;    if tag == &quot;Original&quot;:&#10;        return [(&quot;scaler&quot;, StandardScaler())]&#10;    if tag == &quot;Threshold-Filtered&quot;:&#10;        return [(&quot;scaler&quot;, StandardScaler()), (&quot;variance&quot;, VarianceThreshold(0.5))]&#10;    if tag == &quot;Threshold-Filtered (log)&quot;:&#10;        return [&#10;            (&quot;log&quot;, FunctionTransformer(np.log1p, validate=True)),&#10;            (&quot;variance&quot;, VarianceThreshold(0.5)),&#10;        ]&#10;    if tag == &quot;Selection-Top-350&quot;:&#10;        return [(&quot;scaler&quot;, StandardScaler()), (&quot;topk&quot;, TopKVarianceSelector(k=350))]&#10;    if tag == &quot;Selection-Top-350 (log)&quot;:&#10;        return [&#10;            (&quot;log&quot;, FunctionTransformer(np.log1p, validate=True)),&#10;            (&quot;topk&quot;, TopKVarianceSelector(k=350)),&#10;        ]&#10;    if tag == &quot;Filtered-UMAP&quot;:&#10;        return [&#10;            (&quot;scaler&quot;, StandardScaler()),&#10;            (&quot;umap&quot;, UMAPTransformer(&#10;                n_components=100, n_neighbors=5, min_dist=1.0, random_state=42&#10;            ))&#10;        ]&#10;    raise ValueError(f&quot;Unknown tag {tag}&quot;)&#10;&#10;&#10;def get_model_path(tag, model_name):&#10;    tag_dir = os.path.join(model_dir, tag)&#10;    if not os.path.exists(tag_dir):&#10;        os.makedirs(tag_dir)&#10;    return os.path.join(tag_dir, f&quot;{model_name}.joblib&quot;)&#10;&#10;&#10;def get_metrics_path(tag, model_name):&#10;    tag_dir = os.path.join(model_dir, tag)&#10;    if not os.path.exists(tag_dir):&#10;        os.makedirs(tag_dir)&#10;    return os.path.join(tag_dir, f&quot;{model_name}_metrics.joblib&quot;)&#10;&#10;&#10;def fit_and_store_model(df, pipeline_steps, model_cls, model_kwargs, tag, model_name, seed=42):&#10;    X = df.drop(columns=&quot;Class&quot;)&#10;    y = df[&quot;Class&quot;].values&#10;    orig_feats = X.columns.to_list()&#10;    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)&#10;    accs = []&#10;    bal_accs = []&#10;    precs = []&#10;    recs = []&#10;    f1s = []&#10;    all_true = []&#10;    all_pred = []&#10;&#10;    for tr, te in kf.split(X, y):&#10;        pipe = Pipeline(pipeline_steps + [(&quot;clf&quot;, model_cls(**model_kwargs))])&#10;        pipe.fit(X.iloc[tr], y[tr])&#10;        preds = pipe.predict(X.iloc[te])&#10;        all_true.extend(y[te])&#10;        all_pred.extend(preds)&#10;        accs.append(accuracy_score(y[te], preds))&#10;        bal_accs.append(balanced_accuracy_score(y[te], preds))&#10;        precs.append(precision_score(y[te], preds, average=&quot;weighted&quot;))&#10;        recs.append(recall_score(y[te], preds, average=&quot;weighted&quot;))&#10;        f1s.append(f1_score(y[te], preds, average=&quot;weighted&quot;))&#10;&#10;    # Train final model on all data&#10;    full_pipe = Pipeline(pipeline_steps + [(&quot;clf&quot;, model_cls(**model_kwargs))])&#10;    full_pipe.fit(X, y)&#10;&#10;    # Save model pipeline to disk&#10;    joblib.dump(full_pipe, get_model_path(tag, model_name))&#10;&#10;    # Save metrics to disk&#10;    cm = confusion_matrix(all_true, all_pred, labels=np.unique(y))&#10;    report = classification_report(all_true, all_pred)&#10;    y_shuf = y.copy()&#10;    rng = np.random.RandomState(seed)&#10;    rng.shuffle(y_shuf)&#10;    shuf_accs = []&#10;    for tr, te in kf.split(X, y_shuf):&#10;        pipe = Pipeline(pipeline_steps + [(&quot;clf&quot;, model_cls(**model_kwargs))])&#10;        pipe.fit(X.iloc[tr], y_shuf[tr])&#10;        shuf_accs.append(accuracy_score(y_shuf[te], pipe.predict(X.iloc[te])))&#10;    baseline = float((pd.Series(y).value_counts(normalize=True) ** 2).sum())&#10;    metrics = {&#10;        &quot;metrics&quot;: {&#10;            &quot;Accuracy&quot;: np.mean(accs),&#10;            &quot;Balanced Accuracy&quot;: np.mean(bal_accs),&#10;            &quot;Precision&quot;: np.mean(precs),&#10;            &quot;Recall&quot;: np.mean(recs),&#10;            &quot;F1 Score&quot;: np.mean(f1s),&#10;        },&#10;        &quot;confusion_matrix&quot;: cm,&#10;        &quot;classification_report&quot;: report,&#10;        &quot;shuffle&quot;: {&#10;            &quot;baseline&quot;: baseline,&#10;            &quot;shuffled_acc&quot;: np.mean(shuf_accs),&#10;            &quot;shuffled_std&quot;: np.std(shuf_accs)&#10;        }&#10;    }&#10;    joblib.dump(metrics, get_metrics_path(tag, model_name))&#10;&#10;&#10;def load_model_pipeline(tag, model_name):&#10;    path = get_model_path(tag, model_name)&#10;    if not os.path.exists(path):&#10;        return None&#10;    return joblib.load(path)&#10;&#10;&#10;def load_model_metrics(tag, model_name):&#10;    path = get_metrics_path(tag, model_name)&#10;    if not os.path.exists(path):&#10;        return None&#10;    return joblib.load(path)&#10;&#10;# ────────────────────────────────────────────&#10;# Main page layout with selectbox instead of segmented control&#10;# ────────────────────────────────────────────&#10;st.title(&quot;Cancer Subtype Analysis: EDA + Modeling&quot;)&#10;&#10;section = st.selectbox(&#10;    &quot;Select Section:&quot;,&#10;    options=[&quot;Data Overview&quot;, &quot;Clustering Analysis&quot;, &quot;Model Evaluation&quot;, &quot;SHAP Explanations&quot;, &quot;Clinical Predictor&quot;, &quot;Project Findings&quot;],&#10;    index=0,&#10;    key=&quot;section&quot;&#10;)&#10;&#10;# DATA OVERVIEW SECTION&#10;if section == &quot;Data Overview&quot;:&#10;    st.subheader(&quot;Basic Exploratory Data Analysis&quot;)&#10;    df = load_data()&#10;    st.write(&quot;Merged shape:&quot;, df.shape)&#10;    st.write(&quot;Class counts:&quot;, df[&quot;Class&quot;].value_counts())&#10;    st.write(&quot;Missing values:&quot;, int(df.isna().sum().sum()))&#10;&#10;    fig, ax = plt.subplots(figsize=(6, 4))&#10;    sns.countplot(x=&quot;Class&quot;, data=df, ax=ax)&#10;    st.pyplot(fig)&#10;&#10;    variances = df.drop(columns=&quot;Class&quot;).var()&#10;    st.write(&quot;Variance summary:&quot;, variances.describe())&#10;    fig, ax = plt.subplots(figsize=(8, 4))&#10;    sns.histplot(variances, bins=100, kde=True, ax=ax)&#10;    st.pyplot(fig)&#10;&#10;# CLUSTERING ANALYSIS SECTION&#10;elif section == &quot;Clustering Analysis&quot;:&#10;    st.subheader(&quot;Clustering Analysis&quot;)&#10;    clustering_tabs = st.tabs(tags)&#10;    for i, tag in enumerate(tags):&#10;        with clustering_tabs[i]:&#10;            st.subheader(f&quot;Pipeline: {tag}&quot;)&#10;            X2d, clusters, Xfull, labels = compute_eda(tag)&#10;            plot_step(tag, X2d, clusters, Xfull, labels)&#10;&#10;# MODEL EVALUATION SECTION&#10;elif section == &quot;Model Evaluation&quot;:&#10;    st.subheader(&quot;Model Evaluation&quot;)&#10;&#10;    df = load_data()&#10;    # Model training with progress bar if missing, otherwise use existing&#10;    total_tasks = len(tags) * len(model_specs)&#10;    progress = st.progress(0)&#10;    count = 0&#10;    for tag in tags:&#10;        steps = get_pipeline(tag)&#10;        for cls, kw, model_name in model_specs:&#10;            if not os.path.exists(get_model_path(tag, model_name)):&#10;                with st.spinner(f&quot;Training {model_name} for {tag}...&quot;):&#10;                    fit_and_store_model(df, steps, cls, kw, tag, model_name)&#10;            count += 1&#10;            progress.progress(count / total_tasks)&#10;&#10;    # UI: Tabs for each pipeline&#10;    model_tabs = st.tabs(tags)&#10;    for i, tag in enumerate(tags):&#10;        with model_tabs[i]:&#10;            st.subheader(f&quot;Models with {tag} Pipeline&quot;)&#10;            model_names = [m[2] for m in model_specs]&#10;            model_sub_tabs = st.tabs(model_names)&#10;            for j, model_name in enumerate(model_names):&#10;                with model_sub_tabs[j]:&#10;                    metrics = load_model_metrics(tag, model_name)&#10;                    if metrics is None:&#10;                        st.error(&quot;Model metrics not found, please retrain.&quot;)&#10;                        continue&#10;                    st.write(&quot;Performance Metrics:&quot;)&#10;                    st.write(metrics[&quot;metrics&quot;])&#10;&#10;                    col1, col2 = st.columns(2)&#10;                    with col1:&#10;                        st.subheader(&quot;Confusion Matrix&quot;)&#10;                        cm = metrics[&quot;confusion_matrix&quot;]&#10;                        labels = np.unique(df[&quot;Class&quot;])&#10;                        fig_cm, ax_cm = plt.subplots(figsize=(6, 5))&#10;                        ConfusionMatrixDisplay(cm, display_labels=labels).plot(&#10;                            ax=ax_cm, cmap=&quot;Blues&quot;, xticks_rotation=45&#10;                        )&#10;                        plt.close(fig_cm)&#10;                        st.pyplot(fig_cm)&#10;                    with col2:&#10;                        st.subheader(&quot;Classification Report&quot;)&#10;                        st.text(metrics[&quot;classification_report&quot;])&#10;&#10;                    sh = metrics[&quot;shuffle&quot;]&#10;                    st.write(f&quot;Baseline ∑pᵢ²: {sh['baseline']:.3f}&quot;)&#10;                    st.write(f&quot;Shuffled‑label acc: {sh['shuffled_acc']:.3f} ± {sh['shuffled_std']:.3f}&quot;)&#10;                    if sh[&quot;shuffled_acc&quot;] &lt; sh[&quot;baseline&quot;] - 0.01:&#10;                        st.warning(&quot;⚠️ Shuffled‑label accuracy below theoretical baseline — check CV or leakage.&quot;)&#10;&#10;# SHAP EXPLANATIONS SECTION&#10;elif section == &quot;SHAP Explanations&quot;:&#10;    st.subheader(&quot;SHAP Feature Importance&quot;)&#10;    col1, col2 = st.columns(2)&#10;    with col1:&#10;        selected_tag = st.selectbox(&quot;Select Pipeline&quot;, tags)&#10;    with col2:&#10;        model_names = [m[2] for m in model_specs]&#10;        selected_model = st.selectbox(&quot;Select Model&quot;, model_names)&#10;&#10;    df = load_data()&#10;    model_pipe = load_model_pipeline(selected_tag, selected_model)&#10;    if model_pipe is None:&#10;        st.info(&quot;Model not found. Please visit the Model Evaluation tab to train and store models first.&quot;)&#10;    else:&#10;        X = df.drop(columns=&quot;Class&quot;)&#10;        y = df[&quot;Class&quot;].values&#10;        preproc = model_pipe[:-1]&#10;        clf = model_pipe.named_steps[&quot;clf&quot;]&#10;        orig_feats = X.columns.to_list()&#10;&#10;        feat_names = orig_feats&#10;&#10;        try:&#10;            explainer = shap.Explainer(clf, preproc.transform(X))&#10;            sv = explainer(preproc.transform(X))&#10;            fig_shap = plt.figure()&#10;            shap.summary_plot(&#10;                sv,&#10;                features=preproc.transform(X),&#10;                feature_names=feat_names,&#10;                class_names=clf.classes_,&#10;                plot_type=&quot;bar&quot;, max_display=20, show=False&#10;            )&#10;            plt.close(fig_shap)&#10;            st.pyplot(fig_shap)&#10;            st.write(&quot;SHAP values show the contribution of each feature to the model prediction.&quot;)&#10;        except Exception as e:&#10;            fig_shap = plt.figure()&#10;            plt.text(0.5, 0.5, f&quot;SHAP unavailable\n{e}&quot;, ha=&quot;center&quot;)&#10;            plt.close(fig_shap)&#10;            st.pyplot(fig_shap)&#10;            st.info(&quot;SHAP explanation unavailable for this model/feature set.&quot;)&#10;&#10;# CLINICAL PREDICTOR SECTION - Only section with sidebar&#10;elif section == &quot;Clinical Predictor&quot;:&#10;    st.header(&quot; Cancer Subtype Clinical Predictor&quot;)&#10;    st.markdown(&quot;---&quot;)&#10;    st.markdown(&quot;### Clinical Decision Support Tool&quot;)&#10;    st.markdown(&quot;Enter gene expression values to predict cancer subtype using machine learning models.&quot;)&#10;&#10;    # Load data to get gene information&#10;    df = load_data()&#10;    X = df.drop(columns=&quot;Class&quot;)&#10;    y = df[&quot;Class&quot;]&#10;&#10;    # Sidebar controls - only created in this section&#10;    with st.sidebar:&#10;        st.header(&quot; Clinical Predictor Settings&quot;)&#10;&#10;        # Pipeline selection&#10;        selected_pipeline = st.selectbox(&#10;            &quot; Select Preprocessing Pipeline&quot;,&#10;            options=tags,&#10;            index=2,  # Default to &quot;Threshold-Filtered (log)&quot; - the best performing&#10;            help=&quot;Choose the preprocessing pipeline for feature engineering&quot;&#10;        )&#10;&#10;        # Model selection&#10;        model_names = [m[2] for m in model_specs]&#10;        selected_model = st.selectbox(&#10;            &quot; Select Classification Model&quot;,&#10;            options=model_names,&#10;            index=2,  # Default to &quot;SGD Classifier&quot; - the best performing&#10;            help=&quot;Choose the machine learning model for prediction&quot;&#10;        )&#10;&#10;        st.markdown(&quot;---&quot;)&#10;&#10;        # Number of genes to display&#10;        num_genes = st.slider(&quot;Number of Top Genes to Display&quot;,&#10;                              min_value=5, max_value=50,&#10;                              value=20, step=5,&#10;                              help=&quot;Select how many top variance genes to display for input&quot;)&#10;&#10;        st.markdown(&quot;---&quot;)&#10;        st.markdown(&quot;** Tips:**&quot;)&#10;        st.markdown(&quot;• Use median values as a starting point&quot;)&#10;        st.markdown(&quot;• Try the random sample button for real patient data&quot;)&#10;        st.markdown(&quot;• Adjust individual gene values to see prediction changes&quot;)&#10;        st.markdown(&quot;• Compare different pipeline/model combinations&quot;)&#10;&#10;    # Load the selected model&#10;    @st.cache_data&#10;    def load_selected_model(pipeline_tag, model_name):&#10;        # Try to load the pre-trained model&#10;        model_pipeline = load_model_pipeline(pipeline_tag, model_name)&#10;        model_metrics = load_model_metrics(pipeline_tag, model_name)&#10;&#10;        if model_pipeline is None:&#10;            # If model doesn't exist, train it&#10;            pipeline_steps = get_pipeline(pipeline_tag)&#10;            model_cls, model_kwargs, _ = next((cls, kw, name) for cls, kw, name in model_specs if name == model_name)&#10;&#10;            # Train the model&#10;            fit_and_store_model(df, pipeline_steps, model_cls, model_kwargs, pipeline_tag, model_name)&#10;            model_pipeline = load_model_pipeline(pipeline_tag, model_name)&#10;            model_metrics = load_model_metrics(pipeline_tag, model_name)&#10;&#10;        return model_pipeline, model_metrics&#10;&#10;&#10;    # Load the selected model&#10;    with st.spinner(f&quot;Loading {selected_model} with {selected_pipeline} pipeline...&quot;):&#10;        current_model, current_metrics = load_selected_model(selected_pipeline, selected_model)&#10;&#10;    # Display model performance in sidebar&#10;    if current_metrics:&#10;        st.sidebar.info(f&quot; **Model Performance:**\n&quot;&#10;                        f&quot;• Accuracy: {current_metrics['metrics']['Accuracy']:.3f}\n&quot;&#10;                        f&quot;• F1 Score: {current_metrics['metrics']['F1 Score']:.3f}\n&quot;&#10;                        f&quot;• Precision: {current_metrics['metrics']['Precision']:.3f}&quot;)&#10;&#10;    # Get pipeline steps for feature preprocessing&#10;    pipeline_steps = get_pipeline(selected_pipeline)&#10;&#10;&#10;    # Get feature names after preprocessing&#10;    @st.cache_data&#10;    def get_processed_features(pipeline_tag):&#10;        steps = get_pipeline(pipeline_tag)&#10;        # Apply preprocessing without the classifier&#10;        temp_pipeline = Pipeline(steps)&#10;        X_transformed = temp_pipeline.fit_transform(X)&#10;&#10;        # Get feature names after preprocessing&#10;        if pipeline_tag in [&quot;Threshold-Filtered (log)&quot;, &quot;Threshold-Filtered&quot;]:&#10;            if pipeline_tag == &quot;Threshold-Filtered (log)&quot;:&#10;                Xlog = np.log1p(X)&#10;                selector = VarianceThreshold(0.5)&#10;                selector.fit(Xlog)&#10;            else:&#10;                selector = VarianceThreshold(0.5)&#10;                selector.fit(X)&#10;            selected_features = X.columns[selector.get_support()].tolist()&#10;        elif pipeline_tag in [&quot;Selection-Top-350 (log)&quot;, &quot;Selection-Top-350&quot;]:&#10;            if pipeline_tag == &quot;Selection-Top-350 (log)&quot;:&#10;                Xlog = np.log1p(X)&#10;                top_features = Xlog.var().sort_values(ascending=False).head(350).index.tolist()&#10;            else:&#10;                top_features = X.var().sort_values(ascending=False).head(350).index.tolist()&#10;            selected_features = top_features&#10;        else:&#10;            selected_features = X.columns.tolist()&#10;&#10;        return selected_features, X_transformed.shape[1]&#10;&#10;&#10;    available_genes, n_features_after_preprocessing = get_processed_features(selected_pipeline)&#10;&#10;    st.sidebar.info(f&quot; Pipeline uses {n_features_after_preprocessing} features after preprocessing&quot;)&#10;&#10;    # Show current selection prominently&#10;    if selected_pipeline == &quot;Threshold-Filtered (log)&quot; and selected_model == &quot;SGD Classifier&quot;:&#10;        st.success(&quot; **Using Best Performing Model:** Threshold-Filtered (log) + SGD Classifier&quot;)&#10;    else:&#10;        st.info(f&quot; **Current Selection:** {selected_pipeline} + {selected_model}&quot;)&#10;&#10;    # Get top genes by variance for user input&#10;    if selected_pipeline.endswith(&quot;(log)&quot;):&#10;        Xlog = np.log1p(X)&#10;        gene_variances = Xlog.var().sort_values(ascending=False)&#10;    else:&#10;        gene_variances = X.var().sort_values(ascending=False)&#10;&#10;    top_genes = gene_variances.head(num_genes).index.tolist()&#10;&#10;    st.markdown(f&quot;### Enter Gene Expression Values (Top {num_genes} Genes by Variance)&quot;)&#10;    st.markdown(&quot;*Typical gene expression values range from 0 to 20. You can use the median values as defaults.*&quot;)&#10;&#10;    # Create input form&#10;    with st.form(&quot;clinical_prediction_form&quot;):&#10;        user_inputs = {}&#10;&#10;        # Create columns for better layout&#10;        cols = st.columns(2)&#10;        for i, gene in enumerate(top_genes):&#10;            col = cols[i % 2]&#10;            with col:&#10;                # Get statistics for this gene&#10;                gene_values = X[gene]&#10;                median_val = float(gene_values.median())&#10;                min_val = float(gene_values.min())&#10;                max_val = float(gene_values.max())&#10;&#10;                user_inputs[gene] = st.number_input(&#10;                    f&quot;{gene}&quot;,&#10;                    min_value=min_val,&#10;                    max_value=max_val,&#10;                    value=median_val,&#10;                    step=0.1,&#10;                    help=f&quot;Range: {min_val:.2f} - {max_val:.2f}, Median: {median_val:.2f}&quot;&#10;                )&#10;&#10;        # Quick preset buttons&#10;        st.markdown(&quot;#### Quick Presets&quot;)&#10;        col1, col2, col3 = st.columns(3)&#10;&#10;        use_median = col1.form_submit_button(&quot; Use Median Values&quot;)&#10;        use_random = col2.form_submit_button(&quot; Use Random Sample&quot;)&#10;        predict_button = col3.form_submit_button(&quot; Predict Cancer Subtype&quot;, type=&quot;primary&quot;)&#10;&#10;        if use_median:&#10;            st.rerun()&#10;&#10;        if use_random:&#10;            # Get a random sample from the dataset&#10;            random_sample = X.sample(n=1, random_state=np.random.randint(0, 1000))&#10;            st.session_state['random_sample'] = random_sample.iloc[0].to_dict()&#10;            st.rerun()&#10;&#10;    # Handle random sample&#10;    if 'random_sample' in st.session_state:&#10;        for gene in top_genes:&#10;            if gene in st.session_state['random_sample']:&#10;                user_inputs[gene] = st.session_state['random_sample'][gene]&#10;        del st.session_state['random_sample']&#10;&#10;    # Make prediction&#10;    if predict_button:&#10;        # Create input dataframe with all original features&#10;        input_data = pd.DataFrame([{gene: 0.0 for gene in X.columns}])&#10;&#10;        # Fill in user inputs&#10;        for gene, value in user_inputs.items():&#10;            input_data[gene] = value&#10;&#10;        # Make prediction using the selected model&#10;        try:&#10;            prediction = current_model.predict(input_data)[0]&#10;            prediction_proba = current_model.predict_proba(input_data)[0]&#10;            confidence = float(max(prediction_proba)) * 100&#10;&#10;            # Display results&#10;            st.markdown(&quot;---&quot;)&#10;            st.markdown(&quot;##  Prediction Results&quot;)&#10;&#10;            # Show which model was used&#10;            st.info(f&quot; **Prediction made using:** {selected_pipeline} + {selected_model}&quot;)&#10;&#10;            # Main prediction&#10;            col1, col2 = st.columns([2, 1])&#10;&#10;            with col1:&#10;                if prediction == &quot;BRCA&quot;:&#10;                    st.success(f&quot;### ️ **Predicted Cancer Subtype: BRCA (Breast Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Breast invasive carcinoma&quot;)&#10;                elif prediction == &quot;KIRC&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: KIRC (Kidney Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Kidney renal clear cell carcinoma&quot;)&#10;                elif prediction == &quot;LUAD&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: LUAD (Lung Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Lung adenocarcinoma&quot;)&#10;                elif prediction == &quot;COAD&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: COAD (Colon Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Colon adenocarcinoma&quot;)&#10;                elif prediction == &quot;PRAD&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: PRAD (Prostate Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Prostate adenocarcinoma&quot;)&#10;                else:&#10;                    st.info(f&quot;###  **Predicted Cancer Subtype: {prediction}**&quot;)&#10;&#10;            with col2:&#10;                st.metric(&quot;Confidence&quot;, f&quot;{confidence:.1f}%&quot;)&#10;&#10;                if confidence &gt;= 90:&#10;                    st.success(&quot;High Confidence&quot;)&#10;                elif confidence &gt;= 70:&#10;                    st.warning(&quot;Medium Confidence&quot;)&#10;                else:&#10;                    st.error(&quot;Low Confidence&quot;)&#10;&#10;            # Probability distribution&#10;            st.markdown(&quot;###  Prediction Probabilities&quot;)&#10;            prob_df = pd.DataFrame({&#10;                'Cancer Subtype': current_model.classes_,&#10;                'Probability': prediction_proba * 100&#10;            }).sort_values('Probability', ascending=False)&#10;&#10;            # Create a bar chart&#10;            fig, ax = plt.subplots(figsize=(10, 6))&#10;            bars = ax.bar(prob_df['Cancer Subtype'], prob_df['Probability'],&#10;                          color=['#ff6b6b' if x == prediction else '#74c0fc' for x in prob_df['Cancer Subtype']])&#10;            ax.set_ylabel('Probability (%)')&#10;            ax.set_title('Cancer Subtype Prediction Probabilities')&#10;            ax.set_ylim(0, 100)&#10;&#10;            # Add value labels on bars&#10;            for bar, prob in zip(bars, prob_df['Probability']):&#10;                height = bar.get_height()&#10;                ax.text(bar.get_x() + bar.get_width() / 2., height + 1,&#10;                        f'{prob:.1f}%', ha='center', va='bottom')&#10;&#10;            plt.xticks(rotation=45)&#10;            plt.tight_layout()&#10;            st.pyplot(fig)&#10;&#10;            # Clinical recommendations&#10;            st.markdown(&quot;###  Clinical Recommendations&quot;)&#10;            st.info(&quot;&quot;&quot;&#10;            **Important:** This is a research tool for demonstration purposes only. &#10;            - Results should not be used for actual clinical diagnosis&#10;            - Always consult with qualified medical professionals&#10;            - Additional testing and clinical evaluation are required for medical decisions&#10;            - Gene expression analysis should be part of a comprehensive diagnostic workup&#10;            &quot;&quot;&quot;)&#10;&#10;            # Model information with current selection details&#10;            with st.expander(&quot;ℹ️ Model Information&quot;):&#10;                st.markdown(f&quot;&quot;&quot;&#10;                **Model Details:**&#10;                - **Pipeline:** {selected_pipeline}&#10;                - **Algorithm:** {selected_model}&#10;                - **Accuracy:** {current_metrics['metrics']['Accuracy']:.3f}&#10;                - **F1 Score:** {current_metrics['metrics']['F1 Score']:.3f}&#10;                - **Precision:** {current_metrics['metrics']['Precision']:.3f}&#10;                - **Recall:** {current_metrics['metrics']['Recall']:.3f}&#10;                - **Cross-validation:** 3-fold stratified&#10;                - **Features Used:** {n_features_after_preprocessing} genes after preprocessing&#10;                - **Training Samples:** {len(X)} patients across 5 cancer types&#10;                &quot;&quot;&quot;)&#10;&#10;        except Exception as e:&#10;            st.error(f&quot;Prediction failed: {str(e)}&quot;)&#10;            st.error(&quot;Please check your input values and try again.&quot;)&#10;&#10;# PROJECT FINDINGS SECTION&#10;elif section == &quot;Project Findings&quot;:&#10;    st.header(&quot; Project Findings &amp; Analysis Summary&quot;)&#10;&#10;&#10;    # Use cached content to avoid reprocessing&#10;    @st.cache_data&#10;    def get_project_findings_content():&#10;        return {&#10;            &quot;clustering_summary&quot;: &quot;&quot;&quot;&#10;            **Clustering Analysis Results:**&#10;            Through a series of dimensionality reduction and feature selection pipelines—including threshold-based filtering, log transformations, UMAP embeddings, and top-variance gene selection—six K-Means clustering approaches were evaluated. The highest clustering alignment with ground truth was observed in the Threshold-Filtered (log) and Selection-Top-350 (log) pipelines, achieving ARI and NMI scores above 0.99 and strong silhouette values (0.343 and 0.372, respectively), indicating tight, well-separated clusters. The UMAP-based pipeline, while slightly lower in ARI, exhibited the best 2D structure (silhouette = 0.632), reinforcing its value for visual subtype separation.&#10;            &quot;&quot;&quot;,&#10;            &quot;classification_summary&quot;: &quot;&quot;&quot;&#10;            **Supervised Classification Performance:**&#10;            Supervised classification performance across all pipelines was consistently strong. Each pipeline was evaluated using 3-fold stratified cross-validation, ensuring class balance and robustness in performance metrics. Models were further validated with shuffled-label baselines to detect overfitting or data leakage—most of which showed shuffled accuracy well below theoretical baselines, confirming model integrity. Among traditional classifiers, the SGD Classifier and Random Forest achieved near-perfect scores on several pipelines, with balanced accuracies reaching 1.000 and F1 scores consistently above 0.99. Notably, the Threshold-Filtered (log) pipeline with the SGD Classifier achieved perfect classification (accuracy, precision, recall, and F1 score all equal to 1.000), demonstrating exceptional alignment between preprocessing and modeling.&#10;            &quot;&quot;&quot;,&#10;            &quot;conclusion&quot;: &quot;&quot;&quot;&#10;            **Key Conclusions:**&#10;            Across all pipelines, classification reports showed strong generalization across cancer types such as BRCA, COAD, KIRC, LUAD, and PRAD, with macro-averaged F1-scores approaching 1.0 in most cases. These findings highlight that both unsupervised and supervised models, when properly validated and paired with effective feature transformations, can deliver highly accurate and interpretable cancer subtype predictions.&#10;            &quot;&quot;&quot;&#10;        }&#10;&#10;&#10;    # Get cached content&#10;    content = get_project_findings_content()&#10;&#10;    # Display content efficiently&#10;    st.markdown(&quot;---&quot;)&#10;&#10;    # Create expandable sections for better organization&#10;    with st.expander(&quot; Clustering Analysis Results&quot;, expanded=True):&#10;        st.markdown(content[&quot;clustering_summary&quot;])&#10;&#10;        # Add key metrics summary&#10;        col1, col2, col3 = st.columns(3)&#10;        with col1:&#10;            st.metric(&quot;Best ARI Score&quot;, &quot;&gt; 0.99&quot;, &quot;Threshold-Filtered (log)&quot;)&#10;        with col2:&#10;            st.metric(&quot;Best Silhouette&quot;, &quot;0.632&quot;, &quot;Filtered-UMAP&quot;)&#10;        with col3:&#10;            st.metric(&quot;Clusters Evaluated&quot;, &quot;6&quot;, &quot;Different pipelines&quot;)&#10;&#10;    with st.expander(&quot; Classification Performance&quot;, expanded=True):&#10;        st.markdown(content[&quot;classification_summary&quot;])&#10;&#10;        # Add performance metrics&#10;        col1, col2, col3 = st.columns(3)&#10;        with col1:&#10;            st.metric(&quot;Best Accuracy&quot;, &quot;100%&quot;, &quot;SGD + Threshold-Filtered (log)&quot;)&#10;        with col2:&#10;            st.metric(&quot;CV Folds&quot;, &quot;3&quot;, &quot;Stratified&quot;)&#10;        with col3:&#10;            st.metric(&quot;Cancer Types&quot;, &quot;5&quot;, &quot;BRCA, COAD, KIRC, LUAD, PRAD&quot;)&#10;&#10;    with st.expander(&quot;✅ Key Conclusions&quot;, expanded=True):&#10;        st.markdown(content[&quot;conclusion&quot;])&#10;&#10;        st.success(&#10;            &quot; **Best Performing Model:** Threshold-Filtered (log) + SGD Classifier achieved perfect classification with 100% accuracy across all metrics.&quot;)&#10;&#10;    # Quick reference table&#10;    st.markdown(&quot;---&quot;)&#10;    st.subheader(&quot; Quick Reference: Model Performance Summary&quot;)&#10;&#10;&#10;    @st.cache_data&#10;    def get_performance_table():&#10;        import pandas as pd&#10;        return pd.DataFrame({&#10;            &quot;Pipeline&quot;: [&quot;Threshold-Filtered (log)&quot;, &quot;Selection-Top-350 (log)&quot;, &quot;Filtered-UMAP&quot;, &quot;Original&quot;,&#10;                         &quot;Threshold-Filtered&quot;, &quot;Selection-Top-350&quot;],&#10;            &quot;Best Model&quot;: [&quot;SGD Classifier&quot;, &quot;SGD Classifier&quot;, &quot;Random Forest&quot;, &quot;Random Forest&quot;, &quot;SGD Classifier&quot;,&#10;                           &quot;Random Forest&quot;],&#10;            &quot;Accuracy&quot;: [&quot;100%&quot;, &quot;99.8%&quot;, &quot;99.5%&quot;, &quot;98.9%&quot;, &quot;99.2%&quot;, &quot;99.1%&quot;],&#10;            &quot;ARI Score&quot;: [&quot;&gt;0.99&quot;, &quot;&gt;0.99&quot;, &quot;0.85&quot;, &quot;0.45&quot;, &quot;0.78&quot;, &quot;0.82&quot;],&#10;            &quot;Silhouette&quot;: [&quot;0.343&quot;, &quot;0.372&quot;, &quot;0.632&quot;, &quot;0.156&quot;, &quot;0.234&quot;, &quot;0.289&quot;]&#10;        })&#10;&#10;&#10;    performance_df = get_performance_table()&#10;    st.dataframe(performance_df, use_container_width=True)&#10;&#10;    # Technical details&#10;    st.markdown(&quot;---&quot;)&#10;    with st.expander(&quot; Technical Implementation Details&quot;):&#10;        st.markdown(&quot;&quot;&quot;&#10;        **Methodology:**&#10;        - **Cross-Validation:** 3-fold stratified to ensure class balance&#10;        - **Baseline Validation:** Shuffled-label testing to detect overfitting&#10;        - **Feature Selection:** Variance thresholding (0.5), top-k selection (350)&#10;        - **Dimensionality Reduction:** PCA, UMAP embeddings&#10;        - **Preprocessing:** Log transformation (log1p), standardization&#10;        - **Models Tested:** Decision Tree, Random Forest, SGD Classifier&#10;&#10;        **Dataset Characteristics:**&#10;        - **Samples:** 801 patients across 5 cancer types&#10;        - **Features:** 20,531 genes (original), reduced via preprocessing&#10;        - **Classes:** BRCA, COAD, KIRC, LUAD, PRAD&#10;        - **Balance:** Stratified sampling maintained across folds&#10;        &quot;&quot;&quot;)&#10;" />
              <option name="updatedContent" value="import streamlit as st&#10;import numpy as np&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import os&#10;import sys&#10;from pathlib import Path&#10;from matplotlib.lines import Line2D&#10;from sklearn.cluster import KMeans&#10;from sklearn.preprocessing import StandardScaler, FunctionTransformer&#10;from sklearn.decomposition import PCA&#10;from sklearn.feature_selection import VarianceThreshold&#10;from sklearn.base import BaseEstimator, TransformerMixin&#10;from sklearn.metrics import (&#10;    confusion_matrix, classification_report,&#10;    accuracy_score, balanced_accuracy_score,&#10;    precision_score, recall_score, f1_score,&#10;    ConfusionMatrixDisplay, silhouette_score&#10;)&#10;from sklearn.model_selection import StratifiedKFold&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.ensemble import RandomForestClassifier&#10;from sklearn.linear_model import SGDClassifier&#10;from sklearn.pipeline import Pipeline&#10;&#10;# Add the scripts directory to Python path - safer approach for deployments&#10;ROOT = Path(__file__).resolve().parent.parent&#10;sys.path.append(str(ROOT / &quot;scripts&quot;))&#10;from custom_transformers import UMAPTransformer, TopKVarianceSelector&#10;&#10;import shap&#10;import joblib&#10;&#10;&#10;# Set page config after imports - must be called before any other Streamlit commands&#10;st.set_page_config(initial_sidebar_state=&quot;collapsed&quot;)&#10;&#10;# ────────────────────────────────────────────&#10;# Plot helpers (silhouette removed from evaluate_clusters)&#10;# ────────────────────────────────────────────&#10;def evaluate_clusters(name, X, cluster_labels, true_labels):&#10;    from sklearn.metrics import (&#10;        adjusted_rand_score, normalized_mutual_info_score,&#10;        homogeneity_score, completeness_score, v_measure_score&#10;    )&#10;    y_true = true_labels.astype(str).values&#10;    y_pred = pd.Series(cluster_labels).astype(str)&#10;    scores = {&#10;        &quot;ARI&quot;: adjusted_rand_score(y_true, y_pred),&#10;        &quot;NMI&quot;: normalized_mutual_info_score(y_true, y_pred),&#10;        &quot;Homogeneity&quot;: homogeneity_score(y_true, y_pred),&#10;        &quot;Completeness&quot;: completeness_score(y_true, y_pred),&#10;        &quot;V-measure&quot;: v_measure_score(y_true, y_pred),&#10;    }&#10;    st.write({k: f&quot;{v:.3f}&quot; for k, v in scores.items()})&#10;    # silhouette handled in plot_step&#10;&#10;&#10;def plot_step(name, X2d, clust, Xfull, labels):&#10;    col1, col2 = st.columns(2)&#10;    with col1:&#10;        st.markdown(f&quot;#### {name}: K‑Means clusters&quot;)&#10;        fig, ax = plt.subplots(figsize=(5, 4))&#10;        pts = ax.scatter(X2d[:, 0], X2d[:, 1], c=clust, cmap=&quot;viridis&quot;, alpha=0.6)&#10;        fig.colorbar(pts, ax=ax, label=&quot;Cluster&quot;)&#10;        st.pyplot(fig)&#10;    with col2:&#10;        st.markdown(f&quot;#### {name}: True labels&quot;)&#10;        codes, classes = pd.factorize(labels)&#10;        fig, ax = plt.subplots(figsize=(5, 4))&#10;        ax.scatter(X2d[:, 0], X2d[:, 1], c=codes, cmap=&quot;tab10&quot;, alpha=0.6)&#10;        handles = [&#10;            Line2D([0], [0], marker='o', color='w',&#10;                   markerfacecolor=plt.cm.tab10(i / max(1, len(classes))),&#10;                   label=cls)&#10;            for i, cls in enumerate(classes)&#10;        ]&#10;        ax.legend(handles=handles, title=&quot;Class&quot;,&#10;                  bbox_to_anchor=(1.05, 1), loc=&quot;upper left&quot;)&#10;        st.pyplot(fig)&#10;&#10;    # cluster metrics&#10;    evaluate_clusters(name, Xfull, clust, labels)&#10;    # correct silhouette&#10;    if name == &quot;Filtered-UMAP&quot;:&#10;        st.write(f&quot;Silhouette (2D): {silhouette_score(X2d, clust):.3f}&quot;)&#10;    elif Xfull.shape[1] &gt;= 2:&#10;        st.write(f&quot;Silhouette: {silhouette_score(Xfull, clust):.3f}&quot;)&#10;&#10;&#10;# ────────────────────────────────────────────&#10;# Load &amp; merge data (cached)&#10;# ────────────────────────────────────────────&#10;@st.cache_data&#10;def load_data():&#10;    df_x = pd.read_csv(&quot;Data/cancer_subtype_data.csv&quot;)&#10;    df_y = pd.read_csv(&quot;Data/cancer_subtype_labels.csv&quot;)&#10;    df = pd.merge(df_x, df_y).drop(df_x.columns[0], axis=1)&#10;    return df&#10;&#10;&#10;# Common list of tags&#10;tags = [&#10;    &quot;Original&quot;,&#10;    &quot;Threshold-Filtered&quot;,&#10;    &quot;Threshold-Filtered (log)&quot;,&#10;    &quot;Filtered-UMAP&quot;,&#10;    &quot;Selection-Top-350&quot;,&#10;    &quot;Selection-Top-350 (log)&quot;&#10;]&#10;model_dir = &quot;resources/CancerGeneticsModels&quot;&#10;&#10;model_specs = [&#10;    (DecisionTreeClassifier, {}, &quot;Decision Tree&quot;),&#10;    (RandomForestClassifier, {}, &quot;Random Forest&quot;),&#10;    (SGDClassifier, {&quot;loss&quot;: &quot;log_loss&quot;, &quot;penalty&quot;: &quot;l2&quot;, &quot;max_iter&quot;: 1000}, &quot;SGD Classifier&quot;)&#10;]&#10;&#10;&#10;# ────────────────────────────────────────────&#10;# Compute EDA transforms per‑tag (cached)&#10;# ────────────────────────────────────────────&#10;@st.cache_data(show_spinner=False)&#10;def compute_eda(tag: str):&#10;    df = load_data()&#10;    X = df.drop(columns=&quot;Class&quot;)&#10;    y = df[&quot;Class&quot;]&#10;&#10;    if tag == &quot;Original&quot;:&#10;        Xs = StandardScaler().fit_transform(X)&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Threshold-Filtered&quot;:&#10;        sel = VarianceThreshold(0.5).fit(X)&#10;        Xf = X.loc[:, sel.get_support()]&#10;        Xs = StandardScaler().fit_transform(Xf)&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Threshold-Filtered (log)&quot;:&#10;        Xlog = np.log1p(X)&#10;        sel = VarianceThreshold(0.5).fit(Xlog)&#10;        Xf = Xlog.loc[:, sel.get_support()]&#10;        Xs = Xf.values&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Filtered-UMAP&quot;:&#10;        Xs = StandardScaler().fit_transform(X)&#10;        Emb = UMAPTransformer(&#10;            n_components=100, n_neighbors=5, min_dist=1.0, random_state=42&#10;        ).fit_transform(Xs)&#10;        X2d = Emb[:, :2]&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Emb)&#10;        return X2d, cl, Emb, y&#10;&#10;    if tag == &quot;Selection-Top-350&quot;:&#10;        top = X.var().sort_values(ascending=False).head(350).index&#10;        Xf = X[top]&#10;        Xs = StandardScaler().fit_transform(Xf)&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    if tag == &quot;Selection-Top-350 (log)&quot;:&#10;        Xlog = np.log1p(X)&#10;        top = Xlog.var().sort_values(ascending=False).head(350).index&#10;        Xf = Xlog[top]&#10;        Xs = Xf.values&#10;        X2d = PCA(n_components=2, random_state=42).fit_transform(Xs)&#10;        cl = KMeans(n_clusters=5, random_state=42).fit_predict(Xs)&#10;        return X2d, cl, Xs, y&#10;&#10;    raise ValueError(f&quot;Unknown tag {tag}&quot;)&#10;&#10;&#10;# ────────────────────────────────────────────&#10;# Modeling pipelines &amp; model IO helpers&#10;# ────────────────────────────────────────────&#10;def get_pipeline(tag):&#10;    if tag == &quot;Original&quot;:&#10;        return [(&quot;scaler&quot;, StandardScaler())]&#10;    if tag == &quot;Threshold-Filtered&quot;:&#10;        return [(&quot;scaler&quot;, StandardScaler()), (&quot;variance&quot;, VarianceThreshold(0.5))]&#10;    if tag == &quot;Threshold-Filtered (log)&quot;:&#10;        return [&#10;            (&quot;log&quot;, FunctionTransformer(np.log1p, validate=True)),&#10;            (&quot;variance&quot;, VarianceThreshold(0.5)),&#10;        ]&#10;    if tag == &quot;Selection-Top-350&quot;:&#10;        return [(&quot;scaler&quot;, StandardScaler()), (&quot;topk&quot;, TopKVarianceSelector(k=350))]&#10;    if tag == &quot;Selection-Top-350 (log)&quot;:&#10;        return [&#10;            (&quot;log&quot;, FunctionTransformer(np.log1p, validate=True)),&#10;            (&quot;topk&quot;, TopKVarianceSelector(k=350)),&#10;        ]&#10;    if tag == &quot;Filtered-UMAP&quot;:&#10;        return [&#10;            (&quot;scaler&quot;, StandardScaler()),&#10;            (&quot;umap&quot;, UMAPTransformer(&#10;                n_components=100, n_neighbors=5, min_dist=1.0, random_state=42&#10;            ))&#10;        ]&#10;    raise ValueError(f&quot;Unknown tag {tag}&quot;)&#10;&#10;&#10;def get_model_path(tag, model_name):&#10;    tag_dir = os.path.join(model_dir, tag)&#10;    if not os.path.exists(tag_dir):&#10;        os.makedirs(tag_dir)&#10;    return os.path.join(tag_dir, f&quot;{model_name}.joblib&quot;)&#10;&#10;&#10;def get_metrics_path(tag, model_name):&#10;    tag_dir = os.path.join(model_dir, tag)&#10;    if not os.path.exists(tag_dir):&#10;        os.makedirs(tag_dir)&#10;    return os.path.join(tag_dir, f&quot;{model_name}_metrics.joblib&quot;)&#10;&#10;&#10;def fit_and_store_model(df, pipeline_steps, model_cls, model_kwargs, tag, model_name, seed=42):&#10;    X = df.drop(columns=&quot;Class&quot;)&#10;    y = df[&quot;Class&quot;].values&#10;    orig_feats = X.columns.to_list()&#10;    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)&#10;    accs = []&#10;    bal_accs = []&#10;    precs = []&#10;    recs = []&#10;    f1s = []&#10;    all_true = []&#10;    all_pred = []&#10;&#10;    for tr, te in kf.split(X, y):&#10;        pipe = Pipeline(pipeline_steps + [(&quot;clf&quot;, model_cls(**model_kwargs))])&#10;        pipe.fit(X.iloc[tr], y[tr])&#10;        preds = pipe.predict(X.iloc[te])&#10;        all_true.extend(y[te])&#10;        all_pred.extend(preds)&#10;        accs.append(accuracy_score(y[te], preds))&#10;        bal_accs.append(balanced_accuracy_score(y[te], preds))&#10;        precs.append(precision_score(y[te], preds, average=&quot;weighted&quot;))&#10;        recs.append(recall_score(y[te], preds, average=&quot;weighted&quot;))&#10;        f1s.append(f1_score(y[te], preds, average=&quot;weighted&quot;))&#10;&#10;    # Train final model on all data&#10;    full_pipe = Pipeline(pipeline_steps + [(&quot;clf&quot;, model_cls(**model_kwargs))])&#10;    full_pipe.fit(X, y)&#10;&#10;    # Save model pipeline to disk&#10;    joblib.dump(full_pipe, get_model_path(tag, model_name))&#10;&#10;    # Save metrics to disk&#10;    cm = confusion_matrix(all_true, all_pred, labels=np.unique(y))&#10;    report = classification_report(all_true, all_pred)&#10;    y_shuf = y.copy()&#10;    rng = np.random.RandomState(seed)&#10;    rng.shuffle(y_shuf)&#10;    shuf_accs = []&#10;    for tr, te in kf.split(X, y_shuf):&#10;        pipe = Pipeline(pipeline_steps + [(&quot;clf&quot;, model_cls(**model_kwargs))])&#10;        pipe.fit(X.iloc[tr], y_shuf[tr])&#10;        shuf_accs.append(accuracy_score(y_shuf[te], pipe.predict(X.iloc[te])))&#10;    baseline = float((pd.Series(y).value_counts(normalize=True) ** 2).sum())&#10;    metrics = {&#10;        &quot;metrics&quot;: {&#10;            &quot;Accuracy&quot;: np.mean(accs),&#10;            &quot;Balanced Accuracy&quot;: np.mean(bal_accs),&#10;            &quot;Precision&quot;: np.mean(precs),&#10;            &quot;Recall&quot;: np.mean(recs),&#10;            &quot;F1 Score&quot;: np.mean(f1s),&#10;        },&#10;        &quot;confusion_matrix&quot;: cm,&#10;        &quot;classification_report&quot;: report,&#10;        &quot;shuffle&quot;: {&#10;            &quot;baseline&quot;: baseline,&#10;            &quot;shuffled_acc&quot;: np.mean(shuf_accs),&#10;            &quot;shuffled_std&quot;: np.std(shuf_accs)&#10;        }&#10;    }&#10;    joblib.dump(metrics, get_metrics_path(tag, model_name))&#10;&#10;&#10;def load_model_pipeline(tag, model_name):&#10;    path = get_model_path(tag, model_name)&#10;    if not os.path.exists(path):&#10;        return None&#10;    return joblib.load(path)&#10;&#10;&#10;def load_model_metrics(tag, model_name):&#10;    path = get_metrics_path(tag, model_name)&#10;    if not os.path.exists(path):&#10;        return None&#10;    return joblib.load(path)&#10;&#10;# ────────────────────────────────────────────&#10;# Main page layout with selectbox instead of segmented control&#10;# ────────────────────────────────────────────&#10;st.title(&quot;Cancer Subtype Analysis: EDA + Modeling&quot;)&#10;&#10;section = st.selectbox(&#10;    &quot;Select Section:&quot;,&#10;    options=[&quot;Data Overview&quot;, &quot;Clustering Analysis&quot;, &quot;Model Evaluation&quot;, &quot;SHAP Explanations&quot;, &quot;Clinical Predictor&quot;, &quot;Project Findings&quot;],&#10;    index=0,&#10;    key=&quot;section&quot;&#10;)&#10;&#10;# DATA OVERVIEW SECTION&#10;if section == &quot;Data Overview&quot;:&#10;    st.subheader(&quot;Basic Exploratory Data Analysis&quot;)&#10;    df = load_data()&#10;    st.write(&quot;Merged shape:&quot;, df.shape)&#10;    st.write(&quot;Class counts:&quot;, df[&quot;Class&quot;].value_counts())&#10;    st.write(&quot;Missing values:&quot;, int(df.isna().sum().sum()))&#10;&#10;    fig, ax = plt.subplots(figsize=(6, 4))&#10;    sns.countplot(x=&quot;Class&quot;, data=df, ax=ax)&#10;    st.pyplot(fig)&#10;&#10;    variances = df.drop(columns=&quot;Class&quot;).var()&#10;    st.write(&quot;Variance summary:&quot;, variances.describe())&#10;    fig, ax = plt.subplots(figsize=(8, 4))&#10;    sns.histplot(variances, bins=100, kde=True, ax=ax)&#10;    st.pyplot(fig)&#10;&#10;# CLUSTERING ANALYSIS SECTION&#10;elif section == &quot;Clustering Analysis&quot;:&#10;    st.subheader(&quot;Clustering Analysis&quot;)&#10;    clustering_tabs = st.tabs(tags)&#10;    for i, tag in enumerate(tags):&#10;        with clustering_tabs[i]:&#10;            st.subheader(f&quot;Pipeline: {tag}&quot;)&#10;            X2d, clusters, Xfull, labels = compute_eda(tag)&#10;            plot_step(tag, X2d, clusters, Xfull, labels)&#10;&#10;# MODEL EVALUATION SECTION&#10;elif section == &quot;Model Evaluation&quot;:&#10;    st.subheader(&quot;Model Evaluation&quot;)&#10;&#10;    df = load_data()&#10;    # Model training with progress bar if missing, otherwise use existing&#10;    total_tasks = len(tags) * len(model_specs)&#10;    progress = st.progress(0)&#10;    count = 0&#10;    for tag in tags:&#10;        steps = get_pipeline(tag)&#10;        for cls, kw, model_name in model_specs:&#10;            if not os.path.exists(get_model_path(tag, model_name)):&#10;                with st.spinner(f&quot;Training {model_name} for {tag}...&quot;):&#10;                    fit_and_store_model(df, steps, cls, kw, tag, model_name)&#10;            count += 1&#10;            progress.progress(count / total_tasks)&#10;&#10;    # UI: Tabs for each pipeline&#10;    model_tabs = st.tabs(tags)&#10;    for i, tag in enumerate(tags):&#10;        with model_tabs[i]:&#10;            st.subheader(f&quot;Models with {tag} Pipeline&quot;)&#10;            model_names = [m[2] for m in model_specs]&#10;            model_sub_tabs = st.tabs(model_names)&#10;            for j, model_name in enumerate(model_names):&#10;                with model_sub_tabs[j]:&#10;                    metrics = load_model_metrics(tag, model_name)&#10;                    if metrics is None:&#10;                        st.error(&quot;Model metrics not found, please retrain.&quot;)&#10;                        continue&#10;                    st.write(&quot;Performance Metrics:&quot;)&#10;                    st.write(metrics[&quot;metrics&quot;])&#10;&#10;                    col1, col2 = st.columns(2)&#10;                    with col1:&#10;                        st.subheader(&quot;Confusion Matrix&quot;)&#10;                        cm = metrics[&quot;confusion_matrix&quot;]&#10;                        labels = np.unique(df[&quot;Class&quot;])&#10;                        fig_cm, ax_cm = plt.subplots(figsize=(6, 5))&#10;                        ConfusionMatrixDisplay(cm, display_labels=labels).plot(&#10;                            ax=ax_cm, cmap=&quot;Blues&quot;, xticks_rotation=45&#10;                        )&#10;                        plt.close(fig_cm)&#10;                        st.pyplot(fig_cm)&#10;                    with col2:&#10;                        st.subheader(&quot;Classification Report&quot;)&#10;                        st.text(metrics[&quot;classification_report&quot;])&#10;&#10;                    sh = metrics[&quot;shuffle&quot;]&#10;                    st.write(f&quot;Baseline ∑pᵢ²: {sh['baseline']:.3f}&quot;)&#10;                    st.write(f&quot;Shuffled‑label acc: {sh['shuffled_acc']:.3f} ± {sh['shuffled_std']:.3f}&quot;)&#10;                    if sh[&quot;shuffled_acc&quot;] &lt; sh[&quot;baseline&quot;] - 0.01:&#10;                        st.warning(&quot;⚠️ Shuffled‑label accuracy below theoretical baseline — check CV or leakage.&quot;)&#10;&#10;# SHAP EXPLANATIONS SECTION&#10;elif section == &quot;SHAP Explanations&quot;:&#10;    st.subheader(&quot;SHAP Feature Importance&quot;)&#10;    col1, col2 = st.columns(2)&#10;    with col1:&#10;        selected_tag = st.selectbox(&quot;Select Pipeline&quot;, tags)&#10;    with col2:&#10;        model_names = [m[2] for m in model_specs]&#10;        selected_model = st.selectbox(&quot;Select Model&quot;, model_names)&#10;&#10;    df = load_data()&#10;    model_pipe = load_model_pipeline(selected_tag, selected_model)&#10;    if model_pipe is None:&#10;        st.info(&quot;Model not found. Please visit the Model Evaluation tab to train and store models first.&quot;)&#10;    else:&#10;        X = df.drop(columns=&quot;Class&quot;)&#10;        y = df[&quot;Class&quot;].values&#10;        preproc = model_pipe[:-1]&#10;        clf = model_pipe.named_steps[&quot;clf&quot;]&#10;        orig_feats = X.columns.to_list()&#10;&#10;        feat_names = orig_feats&#10;&#10;        try:&#10;            explainer = shap.Explainer(clf, preproc.transform(X))&#10;            sv = explainer(preproc.transform(X))&#10;            fig_shap = plt.figure()&#10;            shap.summary_plot(&#10;                sv,&#10;                features=preproc.transform(X),&#10;                feature_names=feat_names,&#10;                class_names=clf.classes_,&#10;                plot_type=&quot;bar&quot;, max_display=20, show=False&#10;            )&#10;            plt.close(fig_shap)&#10;            st.pyplot(fig_shap)&#10;            st.write(&quot;SHAP values show the contribution of each feature to the model prediction.&quot;)&#10;        except Exception as e:&#10;            fig_shap = plt.figure()&#10;            plt.text(0.5, 0.5, f&quot;SHAP unavailable\n{e}&quot;, ha=&quot;center&quot;)&#10;            plt.close(fig_shap)&#10;            st.pyplot(fig_shap)&#10;            st.info(&quot;SHAP explanation unavailable for this model/feature set.&quot;)&#10;&#10;# CLINICAL PREDICTOR SECTION - Only section with sidebar&#10;elif section == &quot;Clinical Predictor&quot;:&#10;    st.header(&quot; Cancer Subtype Clinical Predictor&quot;)&#10;    st.markdown(&quot;---&quot;)&#10;    st.markdown(&quot;### Clinical Decision Support Tool&quot;)&#10;    st.markdown(&quot;Enter gene expression values to predict cancer subtype using machine learning models.&quot;)&#10;&#10;    # Load data to get gene information&#10;    df = load_data()&#10;    X = df.drop(columns=&quot;Class&quot;)&#10;    y = df[&quot;Class&quot;]&#10;&#10;    # Sidebar controls - only created in this section&#10;    with st.sidebar:&#10;        st.header(&quot; Clinical Predictor Settings&quot;)&#10;&#10;        # Pipeline selection&#10;        selected_pipeline = st.selectbox(&#10;            &quot; Select Preprocessing Pipeline&quot;,&#10;            options=tags,&#10;            index=2,  # Default to &quot;Threshold-Filtered (log)&quot; - the best performing&#10;            help=&quot;Choose the preprocessing pipeline for feature engineering&quot;&#10;        )&#10;&#10;        # Model selection&#10;        model_names = [m[2] for m in model_specs]&#10;        selected_model = st.selectbox(&#10;            &quot; Select Classification Model&quot;,&#10;            options=model_names,&#10;            index=2,  # Default to &quot;SGD Classifier&quot; - the best performing&#10;            help=&quot;Choose the machine learning model for prediction&quot;&#10;        )&#10;&#10;        st.markdown(&quot;---&quot;)&#10;&#10;        # Number of genes to display&#10;        num_genes = st.slider(&quot;Number of Top Genes to Display&quot;,&#10;                              min_value=5, max_value=50,&#10;                              value=20, step=5,&#10;                              help=&quot;Select how many top variance genes to display for input&quot;)&#10;&#10;        st.markdown(&quot;---&quot;)&#10;        st.markdown(&quot;** Tips:**&quot;)&#10;        st.markdown(&quot;• Use median values as a starting point&quot;)&#10;        st.markdown(&quot;• Try the random sample button for real patient data&quot;)&#10;        st.markdown(&quot;• Adjust individual gene values to see prediction changes&quot;)&#10;        st.markdown(&quot;• Compare different pipeline/model combinations&quot;)&#10;&#10;    # Load the selected model&#10;    @st.cache_data&#10;    def load_selected_model(pipeline_tag, model_name):&#10;        # Try to load the pre-trained model&#10;        model_pipeline = load_model_pipeline(pipeline_tag, model_name)&#10;        model_metrics = load_model_metrics(pipeline_tag, model_name)&#10;&#10;        if model_pipeline is None:&#10;            # If model doesn't exist, train it&#10;            pipeline_steps = get_pipeline(pipeline_tag)&#10;            model_cls, model_kwargs, _ = next((cls, kw, name) for cls, kw, name in model_specs if name == model_name)&#10;&#10;            # Train the model&#10;            fit_and_store_model(df, pipeline_steps, model_cls, model_kwargs, pipeline_tag, model_name)&#10;            model_pipeline = load_model_pipeline(pipeline_tag, model_name)&#10;            model_metrics = load_model_metrics(pipeline_tag, model_name)&#10;&#10;        return model_pipeline, model_metrics&#10;&#10;&#10;    # Load the selected model&#10;    with st.spinner(f&quot;Loading {selected_model} with {selected_pipeline} pipeline...&quot;):&#10;        current_model, current_metrics = load_selected_model(selected_pipeline, selected_model)&#10;&#10;    # Display model performance in sidebar&#10;    if current_metrics:&#10;        st.sidebar.info(f&quot; **Model Performance:**\n&quot;&#10;                        f&quot;• Accuracy: {current_metrics['metrics']['Accuracy']:.3f}\n&quot;&#10;                        f&quot;• F1 Score: {current_metrics['metrics']['F1 Score']:.3f}\n&quot;&#10;                        f&quot;• Precision: {current_metrics['metrics']['Precision']:.3f}&quot;)&#10;&#10;    # Get pipeline steps for feature preprocessing&#10;    pipeline_steps = get_pipeline(selected_pipeline)&#10;&#10;&#10;    # Get feature names after preprocessing&#10;    @st.cache_data&#10;    def get_processed_features(pipeline_tag):&#10;        steps = get_pipeline(pipeline_tag)&#10;        # Apply preprocessing without the classifier&#10;        temp_pipeline = Pipeline(steps)&#10;        X_transformed = temp_pipeline.fit_transform(X)&#10;&#10;        # Get feature names after preprocessing&#10;        if pipeline_tag in [&quot;Threshold-Filtered (log)&quot;, &quot;Threshold-Filtered&quot;]:&#10;            if pipeline_tag == &quot;Threshold-Filtered (log)&quot;:&#10;                Xlog = np.log1p(X)&#10;                selector = VarianceThreshold(0.5)&#10;                selector.fit(Xlog)&#10;            else:&#10;                selector = VarianceThreshold(0.5)&#10;                selector.fit(X)&#10;            selected_features = X.columns[selector.get_support()].tolist()&#10;        elif pipeline_tag in [&quot;Selection-Top-350 (log)&quot;, &quot;Selection-Top-350&quot;]:&#10;            if pipeline_tag == &quot;Selection-Top-350 (log)&quot;:&#10;                Xlog = np.log1p(X)&#10;                top_features = Xlog.var().sort_values(ascending=False).head(350).index.tolist()&#10;            else:&#10;                top_features = X.var().sort_values(ascending=False).head(350).index.tolist()&#10;            selected_features = top_features&#10;        else:&#10;            selected_features = X.columns.tolist()&#10;&#10;        return selected_features, X_transformed.shape[1]&#10;&#10;&#10;    available_genes, n_features_after_preprocessing = get_processed_features(selected_pipeline)&#10;&#10;    st.sidebar.info(f&quot; Pipeline uses {n_features_after_preprocessing} features after preprocessing&quot;)&#10;&#10;    # Show current selection prominently&#10;    if selected_pipeline == &quot;Threshold-Filtered (log)&quot; and selected_model == &quot;SGD Classifier&quot;:&#10;        st.success(&quot; **Using Best Performing Model:** Threshold-Filtered (log) + SGD Classifier&quot;)&#10;    else:&#10;        st.info(f&quot; **Current Selection:** {selected_pipeline} + {selected_model}&quot;)&#10;&#10;    # Get top genes by variance for user input&#10;    if selected_pipeline.endswith(&quot;(log)&quot;):&#10;        Xlog = np.log1p(X)&#10;        gene_variances = Xlog.var().sort_values(ascending=False)&#10;    else:&#10;        gene_variances = X.var().sort_values(ascending=False)&#10;&#10;    top_genes = gene_variances.head(num_genes).index.tolist()&#10;&#10;    st.markdown(f&quot;### Enter Gene Expression Values (Top {num_genes} Genes by Variance)&quot;)&#10;    st.markdown(&quot;*Typical gene expression values range from 0 to 20. You can use the median values as defaults.*&quot;)&#10;&#10;    # Create input form&#10;    with st.form(&quot;clinical_prediction_form&quot;):&#10;        user_inputs = {}&#10;&#10;        # Create columns for better layout&#10;        cols = st.columns(2)&#10;        for i, gene in enumerate(top_genes):&#10;            col = cols[i % 2]&#10;            with col:&#10;                # Get statistics for this gene&#10;                gene_values = X[gene]&#10;                median_val = float(gene_values.median())&#10;                min_val = float(gene_values.min())&#10;                max_val = float(gene_values.max())&#10;&#10;                user_inputs[gene] = st.number_input(&#10;                    f&quot;{gene}&quot;,&#10;                    min_value=min_val,&#10;                    max_value=max_val,&#10;                    value=median_val,&#10;                    step=0.1,&#10;                    help=f&quot;Range: {min_val:.2f} - {max_val:.2f}, Median: {median_val:.2f}&quot;&#10;                )&#10;&#10;        # Quick preset buttons&#10;        st.markdown(&quot;#### Quick Presets&quot;)&#10;        col1, col2, col3 = st.columns(3)&#10;&#10;        use_median = col1.form_submit_button(&quot; Use Median Values&quot;)&#10;        use_random = col2.form_submit_button(&quot; Use Random Sample&quot;)&#10;        predict_button = col3.form_submit_button(&quot; Predict Cancer Subtype&quot;, type=&quot;primary&quot;)&#10;&#10;        if use_median:&#10;            st.rerun()&#10;&#10;        if use_random:&#10;            # Get a random sample from the dataset&#10;            random_sample = X.sample(n=1, random_state=np.random.randint(0, 1000))&#10;            st.session_state['random_sample'] = random_sample.iloc[0].to_dict()&#10;            st.rerun()&#10;&#10;    # Handle random sample&#10;    if 'random_sample' in st.session_state:&#10;        for gene in top_genes:&#10;            if gene in st.session_state['random_sample']:&#10;                user_inputs[gene] = st.session_state['random_sample'][gene]&#10;        del st.session_state['random_sample']&#10;&#10;    # Make prediction&#10;    if predict_button:&#10;        # Create input dataframe with all original features&#10;        input_data = pd.DataFrame([{gene: 0.0 for gene in X.columns}])&#10;&#10;        # Fill in user inputs&#10;        for gene, value in user_inputs.items():&#10;            input_data[gene] = value&#10;&#10;        # Make prediction using the selected model&#10;        try:&#10;            prediction = current_model.predict(input_data)[0]&#10;            prediction_proba = current_model.predict_proba(input_data)[0]&#10;            confidence = float(max(prediction_proba)) * 100&#10;&#10;            # Display results&#10;            st.markdown(&quot;---&quot;)&#10;            st.markdown(&quot;##  Prediction Results&quot;)&#10;&#10;            # Show which model was used&#10;            st.info(f&quot; **Prediction made using:** {selected_pipeline} + {selected_model}&quot;)&#10;&#10;            # Main prediction&#10;            col1, col2 = st.columns([2, 1])&#10;&#10;            with col1:&#10;                if prediction == &quot;BRCA&quot;:&#10;                    st.success(f&quot;### ️ **Predicted Cancer Subtype: BRCA (Breast Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Breast invasive carcinoma&quot;)&#10;                elif prediction == &quot;KIRC&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: KIRC (Kidney Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Kidney renal clear cell carcinoma&quot;)&#10;                elif prediction == &quot;LUAD&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: LUAD (Lung Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Lung adenocarcinoma&quot;)&#10;                elif prediction == &quot;COAD&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: COAD (Colon Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Colon adenocarcinoma&quot;)&#10;                elif prediction == &quot;PRAD&quot;:&#10;                    st.success(f&quot;###  **Predicted Cancer Subtype: PRAD (Prostate Cancer)**&quot;)&#10;                    st.markdown(&quot;**Clinical Information:** Prostate adenocarcinoma&quot;)&#10;                else:&#10;                    st.info(f&quot;###  **Predicted Cancer Subtype: {prediction}**&quot;)&#10;&#10;            with col2:&#10;                st.metric(&quot;Confidence&quot;, f&quot;{confidence:.1f}%&quot;)&#10;&#10;                if confidence &gt;= 90:&#10;                    st.success(&quot;High Confidence&quot;)&#10;                elif confidence &gt;= 70:&#10;                    st.warning(&quot;Medium Confidence&quot;)&#10;                else:&#10;                    st.error(&quot;Low Confidence&quot;)&#10;&#10;            # Probability distribution&#10;            st.markdown(&quot;###  Prediction Probabilities&quot;)&#10;            prob_df = pd.DataFrame({&#10;                'Cancer Subtype': current_model.classes_,&#10;                'Probability': prediction_proba * 100&#10;            }).sort_values('Probability', ascending=False)&#10;&#10;            # Create a bar chart&#10;            fig, ax = plt.subplots(figsize=(10, 6))&#10;            bars = ax.bar(prob_df['Cancer Subtype'], prob_df['Probability'],&#10;                          color=['#ff6b6b' if x == prediction else '#74c0fc' for x in prob_df['Cancer Subtype']])&#10;            ax.set_ylabel('Probability (%)')&#10;            ax.set_title('Cancer Subtype Prediction Probabilities')&#10;            ax.set_ylim(0, 100)&#10;&#10;            # Add value labels on bars&#10;            for bar, prob in zip(bars, prob_df['Probability']):&#10;                height = bar.get_height()&#10;                ax.text(bar.get_x() + bar.get_width() / 2., height + 1,&#10;                        f'{prob:.1f}%', ha='center', va='bottom')&#10;&#10;            plt.xticks(rotation=45)&#10;            plt.tight_layout()&#10;            st.pyplot(fig)&#10;&#10;            # Clinical recommendations&#10;            st.markdown(&quot;###  Clinical Recommendations&quot;)&#10;            st.info(&quot;&quot;&quot;&#10;            **Important:** This is a research tool for demonstration purposes only. &#10;            - Results should not be used for actual clinical diagnosis&#10;            - Always consult with qualified medical professionals&#10;            - Additional testing and clinical evaluation are required for medical decisions&#10;            - Gene expression analysis should be part of a comprehensive diagnostic workup&#10;            &quot;&quot;&quot;)&#10;&#10;            # Model information with current selection details&#10;            with st.expander(&quot;ℹ️ Model Information&quot;):&#10;                st.markdown(f&quot;&quot;&quot;&#10;                **Model Details:**&#10;                - **Pipeline:** {selected_pipeline}&#10;                - **Algorithm:** {selected_model}&#10;                - **Accuracy:** {current_metrics['metrics']['Accuracy']:.3f}&#10;                - **F1 Score:** {current_metrics['metrics']['F1 Score']:.3f}&#10;                - **Precision:** {current_metrics['metrics']['Precision']:.3f}&#10;                - **Recall:** {current_metrics['metrics']['Recall']:.3f}&#10;                - **Cross-validation:** 3-fold stratified&#10;                - **Features Used:** {n_features_after_preprocessing} genes after preprocessing&#10;                - **Training Samples:** {len(X)} patients across 5 cancer types&#10;                &quot;&quot;&quot;)&#10;&#10;        except Exception as e:&#10;            st.error(f&quot;Prediction failed: {str(e)}&quot;)&#10;            st.error(&quot;Please check your input values and try again.&quot;)&#10;&#10;# PROJECT FINDINGS SECTION&#10;elif section == &quot;Project Findings&quot;:&#10;    st.header(&quot; Project Findings &amp; Analysis Summary&quot;)&#10;&#10;&#10;    # Use cached content to avoid reprocessing&#10;    @st.cache_data&#10;    def get_project_findings_content():&#10;        return {&#10;            &quot;clustering_summary&quot;: &quot;&quot;&quot;&#10;            **Clustering Analysis Results:**&#10;            Through a series of dimensionality reduction and feature selection pipelines—including threshold-based filtering, log transformations, UMAP embeddings, and top-variance gene selection—six K-Means clustering approaches were evaluated. The highest clustering alignment with ground truth was observed in the Threshold-Filtered (log) and Selection-Top-350 (log) pipelines, achieving ARI and NMI scores above 0.99 and strong silhouette values (0.343 and 0.372, respectively), indicating tight, well-separated clusters. The UMAP-based pipeline, while slightly lower in ARI, exhibited the best 2D structure (silhouette = 0.632), reinforcing its value for visual subtype separation.&#10;            &quot;&quot;&quot;,&#10;            &quot;classification_summary&quot;: &quot;&quot;&quot;&#10;            **Supervised Classification Performance:**&#10;            Supervised classification performance across all pipelines was consistently strong. Each pipeline was evaluated using 3-fold stratified cross-validation, ensuring class balance and robustness in performance metrics. Models were further validated with shuffled-label baselines to detect overfitting or data leakage—most of which showed shuffled accuracy well below theoretical baselines, confirming model integrity. Among traditional classifiers, the SGD Classifier and Random Forest achieved near-perfect scores on several pipelines, with balanced accuracies reaching 1.000 and F1 scores consistently above 0.99. Notably, the Threshold-Filtered (log) pipeline with the SGD Classifier achieved perfect classification (accuracy, precision, recall, and F1 score all equal to 1.000), demonstrating exceptional alignment between preprocessing and modeling.&#10;            &quot;&quot;&quot;,&#10;            &quot;conclusion&quot;: &quot;&quot;&quot;&#10;            **Key Conclusions:**&#10;            Across all pipelines, classification reports showed strong generalization across cancer types such as BRCA, COAD, KIRC, LUAD, and PRAD, with macro-averaged F1-scores approaching 1.0 in most cases. These findings highlight that both unsupervised and supervised models, when properly validated and paired with effective feature transformations, can deliver highly accurate and interpretable cancer subtype predictions.&#10;            &quot;&quot;&quot;&#10;        }&#10;&#10;&#10;    # Get cached content&#10;    content = get_project_findings_content()&#10;&#10;    # Display content efficiently&#10;    st.markdown(&quot;---&quot;)&#10;&#10;    # Create expandable sections for better organization&#10;    with st.expander(&quot; Clustering Analysis Results&quot;, expanded=True):&#10;        st.markdown(content[&quot;clustering_summary&quot;])&#10;&#10;        # Add key metrics summary&#10;        col1, col2, col3 = st.columns(3)&#10;        with col1:&#10;            st.metric(&quot;Best ARI Score&quot;, &quot;&gt; 0.99&quot;, &quot;Threshold-Filtered (log)&quot;)&#10;        with col2:&#10;            st.metric(&quot;Best Silhouette&quot;, &quot;0.632&quot;, &quot;Filtered-UMAP&quot;)&#10;        with col3:&#10;            st.metric(&quot;Clusters Evaluated&quot;, &quot;6&quot;, &quot;Different pipelines&quot;)&#10;&#10;    with st.expander(&quot; Classification Performance&quot;, expanded=True):&#10;        st.markdown(content[&quot;classification_summary&quot;])&#10;&#10;        # Add performance metrics&#10;        col1, col2, col3 = st.columns(3)&#10;        with col1:&#10;            st.metric(&quot;Best Accuracy&quot;, &quot;100%&quot;, &quot;SGD + Threshold-Filtered (log)&quot;)&#10;        with col2:&#10;            st.metric(&quot;CV Folds&quot;, &quot;3&quot;, &quot;Stratified&quot;)&#10;        with col3:&#10;            st.metric(&quot;Cancer Types&quot;, &quot;5&quot;, &quot;BRCA, COAD, KIRC, LUAD, PRAD&quot;)&#10;&#10;    with st.expander(&quot;✅ Key Conclusions&quot;, expanded=True):&#10;        st.markdown(content[&quot;conclusion&quot;])&#10;&#10;        st.success(&#10;            &quot; **Best Performing Model:** Threshold-Filtered (log) + SGD Classifier achieved perfect classification with 100% accuracy across all metrics.&quot;)&#10;&#10;    # Quick reference table&#10;    st.markdown(&quot;---&quot;)&#10;    st.subheader(&quot; Quick Reference: Model Performance Summary&quot;)&#10;&#10;&#10;    @st.cache_data&#10;    def get_performance_table():&#10;        import pandas as pd&#10;        return pd.DataFrame({&#10;            &quot;Pipeline&quot;: [&quot;Threshold-Filtered (log)&quot;, &quot;Selection-Top-350 (log)&quot;, &quot;Filtered-UMAP&quot;, &quot;Original&quot;,&#10;                         &quot;Threshold-Filtered&quot;, &quot;Selection-Top-350&quot;],&#10;            &quot;Best Model&quot;: [&quot;SGD Classifier&quot;, &quot;SGD Classifier&quot;, &quot;Random Forest&quot;, &quot;Random Forest&quot;, &quot;SGD Classifier&quot;,&#10;                           &quot;Random Forest&quot;],&#10;            &quot;Accuracy&quot;: [&quot;100%&quot;, &quot;99.8%&quot;, &quot;99.5%&quot;, &quot;98.9%&quot;, &quot;99.2%&quot;, &quot;99.1%&quot;],&#10;            &quot;ARI Score&quot;: [&quot;&gt;0.99&quot;, &quot;&gt;0.99&quot;, &quot;0.85&quot;, &quot;0.45&quot;, &quot;0.78&quot;, &quot;0.82&quot;],&#10;            &quot;Silhouette&quot;: [&quot;0.343&quot;, &quot;0.372&quot;, &quot;0.632&quot;, &quot;0.156&quot;, &quot;0.234&quot;, &quot;0.289&quot;]&#10;        })&#10;&#10;&#10;    performance_df = get_performance_table()&#10;    st.dataframe(performance_df, use_container_width=True)&#10;&#10;    # Technical details&#10;    st.markdown(&quot;---&quot;)&#10;    with st.expander(&quot; Technical Implementation Details&quot;):&#10;        st.markdown(&quot;&quot;&quot;&#10;        **Methodology:**&#10;        - **Cross-Validation:** 3-fold stratified to ensure class balance&#10;        - **Baseline Validation:** Shuffled-label testing to detect overfitting&#10;        - **Feature Selection:** Variance thresholding (0.5), top-k selection (350)&#10;        - **Dimensionality Reduction:** PCA, UMAP embeddings&#10;        - **Preprocessing:** Log transformation (log1p), standardization&#10;        - **Models Tested:** Decision Tree, Random Forest, SGD Classifier&#10;&#10;        **Dataset Characteristics:**&#10;        - **Samples:** 801 patients across 5 cancer types&#10;        - **Features:** 20,531 genes (original), reduced via preprocessing&#10;        - **Classes:** BRCA, COAD, KIRC, LUAD, PRAD&#10;        - **Balance:** Stratified sampling maintained across folds&#10;        &quot;&quot;&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>